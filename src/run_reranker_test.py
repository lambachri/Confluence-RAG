"""
Script pour tester le reranker sans Streamlit

Ce script permet de tester le reranker en mode CLI, sans les problÃ¨mes
d'interfÃ©rence avec Streamlit
"""

import os
import sys
import logging
from pathlib import Path

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('reranker_test')

# Activation du reranker pour ce test
os.environ["USE_RERANKER"] = "True"
os.environ["STREAMLIT_MODE"] = "False"

# Importer HelpDesk
from help_desk import HelpDesk

def test_reranker():
    """Test du reranker avec des requÃªtes types"""
    print("\n===== TEST DU RERANKER =====\n")
    
    # Initialiser le modÃ¨le avec reranker activÃ©
    print("Initialisation du modÃ¨le...")
    model = HelpDesk(new_db=False, use_reranker=True)
    
    # VÃ©rifier si le reranker est bien activÃ©
    if model.use_reranker and model.reranker:
        print("âœ… Reranker activÃ© avec succÃ¨s")
    else:
        print("âŒ Ã‰chec de l'activation du reranker")
        return
    
    # Liste de requÃªtes Ã  tester
    test_queries = [
        "Comment configurer un job dans OpCon?",
        "Quelle est la procÃ©dure pour rÃ©soudre un job bloquÃ©?",
        "Comment vÃ©rifier les logs d'un scheduler?",
        "ProcÃ©dure de contrÃ´le des articles dans M3 vers Cegid"
    ]
    
    # Tester chaque requÃªte
    for query in test_queries:
        print(f"\nğŸ” RequÃªte: '{query}'")
        
        # RÃ©cupÃ©rer les documents avec le reranker
        docs = model.retriever.get_relevant_documents(query)
        print(f"Documents rÃ©cupÃ©rÃ©s: {len(docs)}")
        
        # Utiliser le reranker explicitement
        if model.reranker:
            print("Application du reranking...")
            reranked_docs = model.reranker.rerank(query, docs, top_k=5)
            
            print("\nğŸ“„ Top 5 documents aprÃ¨s reranking:")
            for i, doc in enumerate(reranked_docs[:5]):
                title = doc.metadata.get('title', 'Sans titre')
                print(f"{i+1}. {title} (id: {doc.metadata.get('id', 'N/A')})")
        
        # Obtenir une rÃ©ponse complÃ¨te
        print("\nGÃ©nÃ©ration de la rÃ©ponse...")
        answer, sources = model.retrieval_qa_inference(query, use_context=False)
        
        print("\nğŸ’¬ RÃ©ponse gÃ©nÃ©rÃ©e:")
        print(answer[:150] + "..." if len(answer) > 150 else answer)
        print("\nğŸ“š Sources:")
        print(sources)
        print("\n" + "="*50)

if __name__ == "__main__":
    test_reranker()
